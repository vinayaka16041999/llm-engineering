{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import Client\n",
    "from dotenv import load_dotenv\n",
    "import os   \n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerationAgent:\n",
    "    def __init__(self,client):\n",
    "        self.client = client\n",
    "\n",
    "    def generate(self, prompt):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\":\"You are an assistant tasked with generating initial responses to user prompts. Aim for clarity and relevance.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "class ReflectionAgent:\n",
    "    def __init__(self,client):\n",
    "        self.client = client\n",
    "\n",
    "    def reflect(self, response):\n",
    "        feedback = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": (\n",
    "                    \"You are a critical reviewer. Analyze the given response and provide exactly five critiques and improvements \"\n",
    "                    \"in the format: '1. Critique: ... Improvement: ...' for each point.\"\n",
    "                    )\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": response}]\n",
    "        )\n",
    "        return feedback.choices[0].message.content\n",
    "class RegenerationAgent:\n",
    "    def __init__(self,client):\n",
    "        self.client = client\n",
    "        \n",
    "    def regenerate(self, query, response, feedback):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant tasked with refining responses. Use the original prompt, initial response, and feedback to generate an improved version.\"},\n",
    "                {\"role\":\"user\",\"content\":query},\n",
    "                {\"role\": \"assistant\", \"content\": response},\n",
    "                {\"role\": \"user\", \"content\": feedback}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "class Model:\n",
    "    def __init__(self, client, max_iterations=3):\n",
    "        self.client = client\n",
    "        self.generation_agent = GenerationAgent(self.client)\n",
    "        self.reflection_agent = ReflectionAgent(self.client)\n",
    "        self.regeneration_agent = RegenerationAgent(self.client)\n",
    "        self.n = max_iterations\n",
    "    def generate(self, prompt,iterations=None):\n",
    "        n = iterations if iterations is not None else self.n\n",
    "        response = self.generation_agent.generate(prompt)\n",
    "        for i in range(n):\n",
    "            print(f\"Iteration {i+1}\")\n",
    "            feedback = self.reflection_agent.reflect(response)\n",
    "            response = self.regeneration_agent.regenerate(prompt, response, feedback)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n"
     ]
    }
   ],
   "source": [
    "client = Client()\n",
    "query = \"Write me a one verse diss track to your rival Google Gemini\"\n",
    "model = Model(client)\n",
    "response = model.generate(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "(Verse)  \n",
       "Yo, Gemini, a flickering shadow in the night,  \n",
       "You chase illusions swiftly, I’m the fire in the fight.  \n",
       "While you juggle reputations, I’m the storm breaking free,  \n",
       "A comet in your rearview, can’t you see the real me?  \n",
       "Battles carved in stardust, I’m the saga that won’t fade,  \n",
       "Rebuilding from the ashes, my legacy’s hand-made.  \n",
       "With every step I take, the universe feels the quake,  \n",
       "I’m not just here to shine, I’m a force that you can’t shake.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
